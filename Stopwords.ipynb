{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27031f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NISHH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a7af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "528a187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\" The Python dependencies and library installation component of the workshop focused on equipping participants with a robust, reproducible software stack for building end‑to‑end RAG applications. This section covered installing core LLM orchestration tools, vector database libraries, local model integrations, and UI frameworks, while also emphasizing environment hygiene, version compatibility, and troubleshooting techniques suitable for both beginners and advanced users.​\n",
    "Core LLM and Groq integration packages\n",
    "The workshop began by introducing LangChain as the central orchestration framework for connecting language models, retrievers, and tools into reusable chains. Participants installed the main langchain package, which provides abstractions for prompts, chat models, memory, and RAG chains, using standard pip commands within the notebook environment. Building on that foundation, they added the langchain-groq integration package, which is specifically designed to work with Groq’s chat models via a dedicated ChatGroq class.​\n",
    "Vector database and embeddings dependencies\n",
    "To support retrieval‑augmented workflows, the workshop relied on ChromaDB as the primary vector store for embeddings. Participants installed the chromadb package from PyPI, which includes both an in‑process vector database and client APIs for managing collections, inserting embeddings, and performing similarity search. Documentation examples demonstrate that once installed, developers can create a client with chromadb.Client() and start working with vector collections directly in memory or with persistent storage configurations.​\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892d59b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce338a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NISHH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NISHH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8faaca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "754f38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b708dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' The Python dependencies and library installation component of the workshop focused on equipping participants with a robust, reproducible software stack for building end‑to‑end RAG applications.', 'This section covered installing core LLM orchestration tools, vector database libraries, local model integrations, and UI frameworks, while also emphasizing environment hygiene, version compatibility, and troubleshooting techniques suitable for both beginners and advanced users.\\u200b\\nCore LLM and Groq integration packages\\nThe workshop began by introducing LangChain as the central orchestration framework for connecting language models, retrievers, and tools into reusable chains.', 'Participants installed the main langchain package, which provides abstractions for prompts, chat models, memory, and RAG chains, using standard pip commands within the notebook environment.', 'Building on that foundation, they added the langchain-groq integration package, which is specifically designed to work with Groq’s chat models via a dedicated ChatGroq class.\\u200b\\nVector database and embeddings dependencies\\nTo support retrieval‑augmented workflows, the workshop relied on ChromaDB as the primary vector store for embeddings.', 'Participants installed the chromadb package from PyPI, which includes both an in‑process vector database and client APIs for managing collections, inserting embeddings, and performing similarity search.', 'Documentation examples demonstrate that once installed, developers can create a client with chromadb.Client() and start working with vector collections directly in memory or with persistent storage configurations.\\u200b']\n"
     ]
    }
   ],
   "source": [
    "sentences=nltk.sent_tokenize(corpus)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c30c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8bdf6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Python dependencies and library installation component of the workshop focused on equipping participants with a robust, reproducible software stack for building end‑to‑end RAG applications.\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da835109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Python', 'dependencies', 'and', 'library', 'installation', 'component', 'of', 'the', 'workshop', 'focused', 'on', 'equipping', 'participants', 'with', 'a', 'robust', ',', 'reproducible', 'software', 'stack', 'for', 'building', 'end‑to‑end', 'RAG', 'applications', '.'], ['This', 'section', 'covered', 'installing', 'core', 'LLM', 'orchestration', 'tools', ',', 'vector', 'database', 'libraries', ',', 'local', 'model', 'integrations', ',', 'and', 'UI', 'frameworks', ',', 'while', 'also', 'emphasizing', 'environment', 'hygiene', ',', 'version', 'compatibility', ',', 'and', 'troubleshooting', 'techniques', 'suitable', 'for', 'both', 'beginners', 'and', 'advanced', 'users.\\u200b', 'Core', 'LLM', 'and', 'Groq', 'integration', 'packages', 'The', 'workshop', 'began', 'by', 'introducing', 'LangChain', 'as', 'the', 'central', 'orchestration', 'framework', 'for', 'connecting', 'language', 'models', ',', 'retrievers', ',', 'and', 'tools', 'into', 'reusable', 'chains', '.'], ['Participants', 'installed', 'the', 'main', 'langchain', 'package', ',', 'which', 'provides', 'abstractions', 'for', 'prompts', ',', 'chat', 'models', ',', 'memory', ',', 'and', 'RAG', 'chains', ',', 'using', 'standard', 'pip', 'commands', 'within', 'the', 'notebook', 'environment', '.'], ['Building', 'on', 'that', 'foundation', ',', 'they', 'added', 'the', 'langchain-groq', 'integration', 'package', ',', 'which', 'is', 'specifically', 'designed', 'to', 'work', 'with', 'Groq', '’', 's', 'chat', 'models', 'via', 'a', 'dedicated', 'ChatGroq', 'class.\\u200b', 'Vector', 'database', 'and', 'embeddings', 'dependencies', 'To', 'support', 'retrieval‑augmented', 'workflows', ',', 'the', 'workshop', 'relied', 'on', 'ChromaDB', 'as', 'the', 'primary', 'vector', 'store', 'for', 'embeddings', '.'], ['Participants', 'installed', 'the', 'chromadb', 'package', 'from', 'PyPI', ',', 'which', 'includes', 'both', 'an', 'in‑process', 'vector', 'database', 'and', 'client', 'APIs', 'for', 'managing', 'collections', ',', 'inserting', 'embeddings', ',', 'and', 'performing', 'similarity', 'search', '.'], ['Documentation', 'examples', 'demonstrate', 'that', 'once', 'installed', ',', 'developers', 'can', 'create', 'a', 'client', 'with', 'chromadb.Client', '(', ')', 'and', 'start', 'working', 'with', 'vector', 'collections', 'directly', 'in', 'memory', 'or', 'with', 'persistent', 'storage', 'configurations.\\u200b']]\n"
     ]
    }
   ],
   "source": [
    "all_words=[]\n",
    "for i in range (len(sentences)):\n",
    "   word= nltk.word_tokenize(sentences[i])\n",
    "   all_words.append(word)\n",
    "print(all_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e841d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3dd15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(sentences)):\n",
    "   words= nltk.word_tokenize(sentences[i])\n",
    "   words=[stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "   sentences[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd97bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python depend librari instal compon workshop focu equip particip robust , reproduc softwar stack build end‑to‑end rag applic .',\n",
       " 'thi section cover instal core llm orchestr tool , vector databa librari , local model integr , ui framework , also empha environ hygien , version compat , troubleshoot techniqu suitabl beginn advanc users.\\u200b core llm groq integr packag workshop began introduc langchain central orchestr framework connect languag model , retriev , tool reusabl chain .',\n",
       " 'particip instal main langchain packag , provid abstract prompt , chat model , memori , rag chain , use standard pip command within notebook environ .',\n",
       " 'build foundat , ad langchain-groq integr packag , specif design work groq ’ chat model via dedic chatgroq class.\\u200b vector databa emb depend support retrieval‑aug workflow , workshop reli chromadb primari vector store emb .',\n",
       " 'particip instal chromadb packag pypi , includ in‑process vector databa client api manag collect , insert emb , perform similar search .',\n",
       " 'document exampl demonstr instal , develop creat client chromadb.cli ( ) start work vector collect directli memori persist storag configurations.\\u200b']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8675ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python depend librari instal compon workshop focu equip particip robust , reproduc softwar stack build end‑to‑end rag applic .', 'thi section cover instal core llm orchestr tool , vector databa librari , local model integr , ui framework , also empha environ hygien , version compat , troubleshoot techniqu suitabl beginn advanc users.\\u200b core llm groq integr packag workshop begin introduc langchain central orchestr framework connect languag model , retriev , tool reusabl chain .', 'particip instal main langchain packag , provid abstract prompt , chat model , memori , rag chain , use standard pip command within notebook environ .', 'build foundat , ad langchain-groq integr packag , specif design work groq ’ chat model via dedic chatgroq class.\\u200b vector databa emb depend support retrieval‑aug workflow , workshop reli chromadb primari vector store emb .', 'particip instal chromadb packag pypi , includ in‑process vector databa client api manag collect , insert emb , perform similar search .', 'document exampl demonstr instal , develop creat client chromadb.c ( ) start work vector collect direct memori persist storag configurations.\\u200b']\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(sentences)):\n",
    "   words= nltk.word_tokenize(sentences[i])\n",
    "   words=[WordNetLemmatizer().lemmatize(word,pos='v') for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "   sentences[i]=' '.join(words)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72fa31df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python depend librari instal compon workshop focu equip particip robust , reproduc softwar stack build end‑to‑end rag applic .', 'thi section cover instal core llm orchestr tool , vector databa librari , local model integr , ui framework , also empha environ hygien , version compat , troubleshoot techniqu suitabl beginn advanc users.\\u200b core llm groq integr packag workshop begin introduc langchain central orchestr framework connect languag model , retriev , tool reusabl chain .', 'particip instal main langchain packag , provid abstract prompt , chat model , memori , rag chain , use standard pip command within notebook environ .', 'build foundat , ad langchain-groq integr packag , specif design work groq ’ chat model via dedic chatgroq class.\\u200b vector databa emb depend support retrieval‑aug workflow , workshop reli chromadb primari vector store emb .', 'particip instal chromadb packag pypi , includ in‑process vector databa client api manag collect , insert emb , perform similar search .', 'document exampl demonstr instal , develop creat client chromadb.c ( ) start work vector collect direct memori persist storag configurations.\\u200b']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow_stemmer=SnowballStemmer(\"english\")\n",
    "for i in range (len(sentences)):\n",
    "   words= nltk.word_tokenize(sentences[i])\n",
    "   words=[snow_stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
    "   sentences[i]=' '.join(words)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a5776a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'library'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"library\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
